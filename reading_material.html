<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CCAI9012 - Reading Materials</title>
    <link rel="stylesheet" href="docs-style.css">
</head>
<body>
    <div class="container">
        <nav id="sidebar">
            <div class="sidebar-header">
                <h2>CCAI9012 Toolkit</h2>
            </div>
            <ul class="nav-menu">
                <li><a href="index.html">Home</a></li>
                <li><a href="installation.html">Installation Guide</a></li>
                <li><a href="starter_kits.html">Starter Kits</a></li>
                <li><a href="reading_material.html" class="active">Reading Materials</a></li>
                <li><a href="datasets.html">Datasets Reference</a></li>
                <li><a href="api/index.html">API Documentation</a></li>
            </ul>
        </nav>

        <main id="content">
            <header>
                <h1>Reading Materials</h1>
            </header>

            <section class="intro">
                <p>Curated academic papers and resources organized by learning modules to deepen your understanding of AI concepts, risks, and responsible integration.</p>
            </section>

            <section>
                <h2>Module 1: Foundation</h2>
                <ol>
                    <li>
                        LeCun, Y., Bengio, Y. and Hinton, G. (2015) 'Deep learning', <em>Nature</em>, 521(7553), pp. 436â€“444.
                        Available at: <a href="https://doi.org/10.1038/nature14539" target="_blank">https://doi.org/10.1038/nature14539</a>
                    </li>
                    <li>
                        Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning (Chapter 1). MIT Press.
                        <a href="https://www.deeplearningbook.org/" target="_blank">https://www.deeplearningbook.org/</a>
                    </li>
                    <li>
                        Floridi, L. and Chiriatti, M. (2020) 'GPT-3: Its Nature, Scope, Limits, and Consequences', Minds and Machines, 30(4), pp. 681â€“694.
                        Available at: <a href="https://doi.org/10.1007/s11023-020-09548-1" target="_blank">https://doi.org/10.1007/s11023-020-09548-1</a>
                    </li>
                </ol>
            </section>

            <section>
                <h2>Module 2: Understanding AI Risks</h2>
                <ol>
                    <li>
                        Buolamwini, J. and Gebru, T. (2018) 'Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification',
                        in Proceedings of the 1st Conference on Fairness, Accountability and Transparency. Conference on Fairness, Accountability and Transparency, PMLR, pp. 77â€“91.
                        Available at: <a href="https://proceedings.mlr.press/v81/buolamwini18a.html" target="_blank">https://proceedings.mlr.press/v81/buolamwini18a.html</a>
                    </li>
                    <li>
                        Lipton, Z.C. (2017) 'The Mythos of Model Interpretability'. arXiv.
                        Available at: <a href="https://doi.org/10.48550/arXiv.1606.03490" target="_blank">https://doi.org/10.48550/arXiv.1606.03490</a>
                    </li>
                    <li>
                        Gebru, T., Morgenstern, J., Vecchione, B., et al. (2021). Datasheets for datasets. Communications of the ACM, 64(12), 86â€“92.
                    </li>
                </ol>
            </section>

            <section>
                <h2>Module 3: Responsible AI Integration</h2>
                <ol>
                    <li>
                        Jobin, A., Ienca, M. and Vayena, E. (2019) 'The global landscape of AI ethics guidelines', Nature Machine Intelligence, 1(9), pp. 389â€“399.
                        Available at: <a href="https://doi.org/10.1038/s42256-019-0088-2" target="_blank">https://doi.org/10.1038/s42256-019-0088-2</a>
                    </li>
                    <li>
                        Sutton, R.S., 2019. The bitter lesson. Incomplete Ideas.
                        Available at: <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" target="_blank">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a>
                    </li>
                    <li>
                        Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies, Chapter 2: Paths to Superintelligence
                    </li>
                </ol>
            </section>

            <section>
                <h2>How to Use These Materials</h2>
                <p>These readings are carefully selected to provide both theoretical foundations and practical insights into AI:</p>
                <ul>
                    <li><strong>Module 1 (Foundation)</strong>: Start here to understand the fundamentals of deep learning and modern AI systems</li>
                    <li><strong>Module 2 (Understanding AI Risks)</strong>: Learn about bias, fairness, and interpretability challenges in AI systems</li>
                    <li><strong>Module 3 (Responsible AI Integration)</strong>: Explore ethical frameworks and considerations for deploying AI responsibly</li>
                </ul>

                <div class="info-box">
                    <strong>ðŸ’¡ Tip:</strong> We recommend reading these materials alongside the practical starter kits to see how theoretical concepts translate into real-world applications.
                </div>
            </section>
        </main>
    </div>
</body>
</html>
